{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0-fRl09mRu_U"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import os\n",
    "import time\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy import signal, stats\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F \n",
    "from torch_geometric.nn import GCNConv, TopKPooling, global_mean_pool\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.data import DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LZ2su2IlOZ_A"
   },
   "outputs": [],
   "source": [
    "def getCoherenceAdjacency(sample, channel):\n",
    "\n",
    "    \"\"\"\n",
    "    Get average and stdv of pairwise MS-coherence between\n",
    "    channels on 5 freq ranges.\n",
    "    @param sample: Array, a sample signal of size (640X64)\n",
    "    @param channel: Integer, current channel for pairwise coherence\n",
    "    return: Array, average and stdv of coherence of size (10,)\n",
    "            Array, adjacency vector of size (64,)\n",
    "    \"\"\"\n",
    "\n",
    "    i_Cxy = 0\n",
    "    Cxy_pairwise = np.empty((63, 5))\n",
    "    adjacency_vector = np.zeros((64,))\n",
    "    for other_channel in range(64):\n",
    "        if other_channel == channel:\n",
    "            continue\n",
    "        adjacency_vector[other_channel] = abs(stats.spearmanr(sample[:, channel], sample[:, other_channel])[0])\n",
    "        f, Cxy = signal.coherence(sample[:, channel], sample[:, other_channel], 160, nperseg=80)\n",
    "        alpha_idx = np.where((f >= 8) & (f <= 12))[0]\n",
    "        alpha_mean = Cxy[alpha_idx].mean()\n",
    "\n",
    "        beta_idx = np.where((f >= 12) & (f <= 35))[0]\n",
    "        beta_mean = Cxy[beta_idx].mean()\n",
    "\n",
    "        gamma_idx = np.where(f >= 35)[0]\n",
    "        gamma_mean = Cxy[gamma_idx].mean()\n",
    "\n",
    "        theta_idx = np.where((f >= 4) & (f <= 8))[0]\n",
    "        theta_mean = Cxy[theta_idx].mean()\n",
    "\n",
    "        delta_idx = np.where((f >= 0.5) & (f <= 4))[0]\n",
    "        delta_mean = Cxy[delta_idx].mean()\n",
    "        Cxy_pairwise[i_Cxy] = [delta_mean, theta_mean, alpha_mean, beta_mean, gamma_mean]\n",
    "        i_Cxy += 1\n",
    "\n",
    "    return np.append(Cxy_pairwise.mean(axis=0), Cxy_pairwise.std(axis=0)), adjacency_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ujR-o88SHLXe"
   },
   "outputs": [],
   "source": [
    "def getTimeFeatures(sample):\n",
    "\n",
    "    \"\"\"\n",
    "    Extracts time-domain features from sample signals.\n",
    "    @param sample: Array, a sample signal of size (640X64)\n",
    "    return: Array, time-domain feature matrix of size (64X10)\n",
    "    \"\"\"\n",
    "\n",
    "    # mean absolute value\n",
    "    mav = abs(sample).mean(axis=0)[..., np.newaxis]\n",
    "    # variance\n",
    "    var = np.var(sample, axis=0)[..., np.newaxis]\n",
    "    # mean square root\n",
    "    msr = np.sqrt(abs(sample)).mean(axis=0)[..., np.newaxis]\n",
    "    # root mean square\n",
    "    rms = np.sqrt(np.mean(sample**2, axis=0))[..., np.newaxis]\n",
    "    # log detector\n",
    "    ld = np.exp(np.log(abs(sample)).mean(axis=0))[..., np.newaxis]\n",
    "    # waveform length\n",
    "    wav_len = np.sum(abs(sample[1:, :] - sample[:-1, :]), axis=0)[..., np.newaxis]\n",
    "    # difference absolute standard deviation value\n",
    "    dasdv = np.sqrt(np.mean((sample[1:, :] - sample[:-1, :]) ** 2, axis=0))[..., np.newaxis]\n",
    "    # zero crossing\n",
    "    sample_mul = np.sign(sample[1:, :] * sample[:-1, :])\n",
    "    sample_mul_sgn = np.where(sample_mul==1, 0, sample_mul)\n",
    "    sample_mul_sgn = np.where(sample_mul_sgn==-1, 1, sample_mul_sgn)\n",
    "    sample_diff_sgn = abs(sample[1:, :] - sample[:-1, :]) >= 0.01\n",
    "    nzc = np.logical_and(sample_mul_sgn, sample_diff_sgn).sum(axis=0)[..., np.newaxis]\n",
    "    # skewness\n",
    "    sample_skewness = skew(sample, axis=0)[..., np.newaxis]\n",
    "    # kurtosis\n",
    "    sample_kurtosis = kurtosis(sample, axis=0)[..., np.newaxis]\n",
    "\n",
    "    time_features = np.hstack((mav, var, msr, rms, ld, wav_len, dasdv,\n",
    "                               nzc, sample_skewness, sample_kurtosis))\n",
    "    # normalize\n",
    "    scaler = StandardScaler()\n",
    "    time_features = scaler.fit_transform(time_features)\n",
    "    return time_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "J9BoLGSii2m7"
   },
   "outputs": [],
   "source": [
    "def getFeaturesAdjacency(sample):\n",
    "\n",
    "    \"\"\"\n",
    "    Extracts temporal and spectral features from sample signals.\n",
    "    Calculate Spearman's correlation as weighted adjacency matrix.\n",
    "    @param sample: Array, a sample signal of size (640X64)\n",
    "    return: Array, feature matrix of size (64X25)\n",
    "            Array, adjacency matrix of size (64X64)\n",
    "    \"\"\"\n",
    "\n",
    "    time_features = getTimeFeatures(sample)\n",
    "\n",
    "    freq_features = np.zeros((64, 15))\n",
    "    adjacency_matrix = np.zeros((64, 64))\n",
    "    for channel in range(64):\n",
    "#         f, pxx = signal.welch(sample[:, channel], fs=160, window='hann', nperseg=256, nfft=256)\n",
    "        f, pxx = signal.periodogram(sample[:, channel], 160)\n",
    "        alpha_idx = np.where((f >= 8) & (f <= 12))[0]\n",
    "        alpha_mean = pxx[alpha_idx].mean()\n",
    "\n",
    "        beta_idx = np.where((f >= 12) & (f <= 35))[0]\n",
    "        beta_mean = pxx[beta_idx].mean()\n",
    "\n",
    "        gamma_idx = np.where(f >= 35)[0]\n",
    "        gamma_mean = pxx[gamma_idx].mean()\n",
    "\n",
    "        theta_idx = np.where((f >= 4) & (f <= 8))[0]\n",
    "        theta_mean = pxx[theta_idx].mean()\n",
    "\n",
    "        delta_idx = np.where((f >= 0.5) & (f <= 4))[0]\n",
    "        delta_mean = pxx[delta_idx].mean()\n",
    "\n",
    "        coherence, adjacency_vector = getCoherenceAdjacency(sample, channel)\n",
    "\n",
    "        freq_features_sample = np.array([delta_mean, theta_mean, alpha_mean,\n",
    "                                         beta_mean, gamma_mean])\n",
    "        freq_features[channel] = np.append(freq_features_sample, coherence)\n",
    "        adjacency_matrix[channel, :] = adjacency_vector\n",
    "    \n",
    "    # normalize\n",
    "    scaler = StandardScaler()\n",
    "    freq_features = scaler.fit_transform(freq_features)\n",
    "\n",
    "    return np.hstack((time_features, freq_features)), adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(data, threshold, feature_matrices, edge_index_lst, edge_attr_lst):\n",
    "    \n",
    "    \"\"\"\n",
    "    Extract feature_matrices, edge_indices, edge_attrs for a dataset.\n",
    "    @param data: Array, train, validation, or test signals\n",
    "    @param threshold: Float, threshold for correlation\n",
    "    @param feature_matrices: Array, placeholder for feature matrix of each sample\n",
    "    @param edge_index_lst: List, placeholder for edge index of each sample\n",
    "    @param edge_attr_lst: List, placeholder for edge attributes of each sample\n",
    "    \"\"\"\n",
    "    \n",
    "    for sample_ind in range(data.shape[0]):\n",
    "        if sample_ind % 50 == 0:\n",
    "            print(f'sample_ind: {sample_ind}')\n",
    "        sample = data[sample_ind]\n",
    "        feature_matrix, adjacency_matrix = getFeaturesAdjacency(sample)\n",
    "        feature_matrices[sample_ind] = feature_matrix\n",
    "\n",
    "        # get edge index\n",
    "        edge_index = np.argwhere(adjacency_matrix > threshold).T\n",
    "        # get edge attributes\n",
    "        valid_ind = np.where(adjacency_matrix.ravel() > threshold)[0]\n",
    "        edge_attr = adjacency_matrix.ravel()[valid_ind][..., np.newaxis]\n",
    "        edge_index_lst.append(edge_index)\n",
    "        edge_attr_lst.append(edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(InMemoryDataset):\n",
    "    def __init__(self, root, eeg, tasks, transform=None, pre_transform=None):\n",
    "        self.eeg = eeg\n",
    "        self.y = tasks\n",
    "        super(EEGDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        \n",
    "        data_list = []\n",
    "        for i in range(len(self.eeg.edge_index)):\n",
    "            data = Data(x=torch.FloatTensor(self.eeg.feature_matrix[i]),\n",
    "                    edge_index=torch.tensor(self.eeg.edge_index[i], dtype=torch.long),\n",
    "                    edge_attr=torch.FloatTensor(self.eeg.edge_attr[i]),\n",
    "                    y=torch.tensor(self.y[i]-1, dtype=torch.long))    # save tasks\n",
    "            data_list.append(data)\n",
    "        \n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "        torch.save((self.data, self.slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xprep():\n",
    "    \n",
    "    \"\"\"\n",
    "    Placeholder for normalized feature_matrix, edge_index, and edge_attr\n",
    "    in preparation for GCN Dataset generation.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_matrix, edge_index, edge_attr):\n",
    "        self.feature_matrix = feature_matrix\n",
    "        self.edge_index = edge_index\n",
    "        self.edge_attr = edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bGv7-qVSSKbO"
   },
   "outputs": [],
   "source": [
    "loadPath = '/scratch/qh503/deepLearningProject/data_h5/'\n",
    "savePath = '/scratch/qh503/deepLearningProject/data_GCN/timeFreq25_tr1800val360ts_normExtractNorm_normTimeFreq/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IQafBEnPSsYO"
   },
   "outputs": [],
   "source": [
    "f_train = h5py.File(os.path.join(loadPath, \"train1800_raw_EEG.h5\"), \"r\")\n",
    "tr_data = f_train['data'][:]\n",
    "ytr = f_train['tasks'][:]\n",
    "tr_subjects = f_train['subjects'][:]\n",
    "\n",
    "f_valid = h5py.File(os.path.join(loadPath, \"valid360_raw_EEG.h5\"), \"r\")\n",
    "val_data = f_valid['data'][:]\n",
    "yval = f_valid['tasks'][:]\n",
    "val_subjects = f_valid['subjects'][:]\n",
    "\n",
    "f_test = h5py.File(os.path.join(loadPath, \"test360_raw_EEG.h5\"), \"r\")\n",
    "ts_data = f_test['data'][:]\n",
    "yts = f_test['tasks'][:]\n",
    "ts_subjects = f_test['subjects'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 64)\n",
      "(230400, 64)\n",
      "(230400, 64)\n",
      "(1800, 640, 64)\n",
      "(360, 640, 64)\n",
      "(360, 640, 64)\n"
     ]
    }
   ],
   "source": [
    "# flatten and reshape data\n",
    "xtr_s_flattened = np.squeeze(tr_data).ravel().reshape((-1, 64))\n",
    "xval_s_flattened = np.squeeze(val_data).ravel().reshape((-1, 64))\n",
    "xts_s_flattened = np.squeeze(ts_data).ravel().reshape((-1, 64))\n",
    "print(xtr_s_flattened.shape)\n",
    "print(xval_s_flattened.shape)\n",
    "print(xts_s_flattened.shape)\n",
    "\n",
    "# normalize data\n",
    "scaler = StandardScaler()\n",
    "Ztr_temp = scaler.fit_transform(xtr_s_flattened)\n",
    "Zval_temp = scaler.transform(xval_s_flattened)\n",
    "Zts_temp = scaler.transform(xts_s_flattened)\n",
    "\n",
    "# flatten and reshape data back\n",
    "Ztr = np.squeeze(Ztr_temp).ravel().reshape((-1, 640, 64))\n",
    "Zval = np.squeeze(Zval_temp).ravel().reshape((-1, 640, 64))\n",
    "Zts = np.squeeze(Zts_temp).ravel().reshape((-1, 640, 64))\n",
    "print(Ztr.shape)\n",
    "print(Zval.shape)\n",
    "print(Zts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset processing...\n",
      "sample_ind: 0\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "Xtr = np.empty((tr_data.shape[0], 64, 25))\n",
    "Xval = np.empty((val_data.shape[0], 64, 25))\n",
    "Xts = np.empty((ts_data.shape[0], 64, 25))\n",
    "tr_edge_index, tr_edge_attr = [], []\n",
    "val_edge_index, val_edge_attr = [], []\n",
    "ts_edge_index, ts_edge_attr = [], []\n",
    "print('trainset processing...')\n",
    "extract(Ztr, 0.4, Xtr, tr_edge_index, tr_edge_attr)\n",
    "print('valset processing...')\n",
    "extract(Zval, 0.4, Xval, val_edge_index, val_edge_attr)\n",
    "print('testset processing...')\n",
    "extract(Zts, 0.4, Xts, ts_edge_index, ts_edge_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_eeg = Xprep(Xtr, tr_edge_index, tr_edge_attr)\n",
    "val_eeg = Xprep(Xval, val_edge_index, val_edge_attr)\n",
    "ts_eeg = Xprep(Xts, ts_edge_index, ts_edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = EEGDataset(root=os.path.join(savePath, 'train'), eeg=tr_eeg, tasks=ytr)\n",
    "val_dataset = EEGDataset(root=os.path.join(savePath, 'valid'), eeg=val_eeg, tasks=yval)\n",
    "ts_dataset = EEGDataset(root=os.path.join(savePath, 'test'), eeg=ts_eeg, tasks=yval)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "featureExtraction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
